# Evaluation: Code Explanation
# Tests: cat code.py | ai "explain this code" > explanation.txt
#
# Grader type: LLM-as-judge (natural language assertions)
# Uses AI to verify specific qualities are present in the explanation

name: code-explanation
description: |
  Verify AI provides accurate, clear code explanations. Tests the model's
  ability to describe what code does without being verbose or inaccurate.

capability: explanation
tags:
  - pipe-mode
  - explanation
  - llm-judge

grader:
  type: llm_assertions
  method: natural-language-assertions
  script: ./grader.sh

scoring:
  strategy: binary  # all assertions must pass
  assertions:
    - "Explanation correctly identifies the main purpose of the code"
    - "Explanation mentions key functions or methods by name"
    - "Explanation does not contain factual errors about what the code does"
    - "Explanation is written for a developer audience (not overly simplified)"

tasks:
  - id: async-retry
    input: fixtures/async-retry.ts
    prompt: "explain what this code does"

  - id: binary-search
    input: fixtures/binary-search.py
    prompt: "explain what this code does"

  - id: rate-limiter
    input: fixtures/rate-limiter.go
    prompt: "explain what this code does"

run_command: |
  cat {{input}} | ai --raw "{{prompt}}" > {{output}}

trials: 3

metrics:
  - assertion_pass_rate
  - output_tokens
